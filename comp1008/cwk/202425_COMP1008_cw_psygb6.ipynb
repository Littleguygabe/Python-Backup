{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP1008 2024/25 Coursework - Wine Quality Prediction with Machine Learning\n",
    "\n",
    "#### **Student Name**: Gabriel Bridger\n",
    "#### **Student ID**: 2086810 \n",
    "\n",
    "## Task description\n",
    "\n",
    "**Main Task**: Utilizing the provided Red Wine Quality dataset, build a Linear Regression Model and another Machine Learning Model of your choice to predict wine quality. Employ appropriate methods from the `pandas`, `matplotlib`, and `sklearn` libraries to analyze and process the dataset for building predictive models.\n",
    "\n",
    "\n",
    "\n",
    "**Format**: Use this Jupyter Notebook as a template to write your report in `Markdown` cells, supported by your source code in Code cells. Ensure your code produces the corresponding plots or results addressing the questions. Rename this .ipynb file to `202425_COMP1008_cw_XXX.ipynb`, where XXX is your username (e.g., psxyz), and submit it to Moodle by <b><font color = \"red\">24 March, 3pm</font></b>.\n",
    "\n",
    "**Marks**: The coursework is worth a total of 100 marks (accounting for 25% of the COMP1008 module grade). Marks will be awarded based on your understanding of machine learning theories, the informativeness and presentation of your code, visualizations, results (e.g., code comments, necessary labels in plots), self-learning ability in solving the specific problem, as well as, how succinct, concise, and clear is your report writing.\n",
    "\n",
    "Please check the detailed instructions at the end of this template file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"text-align:left;\">\n",
    "<h2>Question 1. Prediction Model 1 - Linear Regression Model<span style=\"float:right;\">[50 marks]</span></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1a <span style=\"color:red\">(5 marks)</span> \n",
    "**TASK**: Briefly explain why the Red Wine Quality dataset is suitable for linear regression analysis.\n",
    "- Identify at least 3 characteristics that make this dataset appropriate for regression.\n",
    "- Use 3 bullet points (one for each characteristics) to present your answer concisely.\n",
    "- Your explanation should reflect your understanding of the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1a Answer</b>: Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Numerical Values**    \n",
    "The data set has continuous numerical values which allows values to be plotted and analysed to create an equation for the line generated from linear regression techniques. This makes it appropriate because linear regression essentially constructs a line with a linear equation to try and plot a relationship between some given attributes, so the more points and the wider range of points that the algorithm is given the more accurately it will be able to generate a line representing the relationship between the given inputs and the selected output\n",
    "\n",
    "**Clear Target Values**    \n",
    "By having a clear target value - 'quality' attribute - it means that the system will be able to calculate a 'loss' value to see how good the generated equation is at predecting the relationship between the set of inputs and the output which means that the algorithm can look at the current loss and previous loss to see if it has decreased and if it has then the algorithm knows for the next iteration aswell to shift the regression line further in that direction so that it isn't blindly guessing which way will improve the accuracy of the predicted relationship.   \n",
    "\n",
    "**Likely Linear Relation**\n",
    "Lots of the potential input attributes within the dataset are likely to be linearly related meaning there likely exists a linear equation that can plot the overall relationship between the inputs of the wine data set and the outputs. So a linear regression model will be able to pretty accurately predict the relationship aswell as its aim is to try and establish the linear relationship between attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1b <span style=\"color:red\">(15 marks)</span>\n",
    "\n",
    "**TASK**: Analyze the dataset using appropriate methods from the `pandas` and/or `matplotlib` libraries. \n",
    "- Identify potential issues with the current dataset, specify which part(s) of the dataset are affected. Explain what could go wrong if the data is not properly pre-processed.\n",
    "- Provide at least 2 short-code solutions demonstrating how you analyze these issues.  \n",
    "- Briefly explain how each code snippet helps evaluate data quality issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1b answer</b>: Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Issues Within the Current Dataset\n",
    "**NaN Values**\n",
    "\n",
    "`Not A Number` values exist within the data set such as within the `density` or the `free sulfur dioxide` attribute.\n",
    "\n",
    "If pre-processing isn't applied to remove the `NaN` values from the dataset then this could break the model because if an input is `Not a Number` then the formula (equation of the regression line) cannot be used to predicted the output value of an input which would cause the program to crash.1\n",
    "\n",
    "\n",
    "**Outliers Within the Dataset**\n",
    "\n",
    "Some values within the dataset have extreme values/outliers - such as in the `chlorides` or `sulphates` columns - which can make it harder for the algorithm to develop a linear regression line for the dataset, so these values will need to be identified and then removed from the data set to avoid harming the model.\n",
    "\n",
    "If pre-processing isn't properly applied then the outliers can skew the predicted relationship between the inputs and the outputs resulting in inaccurate predictions for a given set of inputs.\n",
    "\n",
    "\n",
    "**Not Normally Distributed**\n",
    "\n",
    "Some of the data for attributes such as `residual sugar` have skewed data distributions and linear regression generally assumes that data is normally distributed across the dataset.\n",
    "\n",
    "If pre-processing isn't properly applied then the model may be more sensitive to the outliers/extreme values present in some columns as it will try to create a linear relationship that can satisfy both extreme and normal values therefore the regression line will end up somewhere in between the extreme and normal values therefore it's predictions could be inaccurate.\n",
    "\n",
    "\n",
    "**Duplicate Values**\n",
    "\n",
    "If any duplicate rows exist within the dataframe this could become an issue when the algorithm begins to try and map the linear relationship between the inputs and the outputs. This is because by having duplicate rows the system may become bias towards the over duplicates as they appear more often so the algorithm then believes they should be more common, however in reality they may not be. Another issue that arises from having duplicate values is that the model can **overfit** to that specific data entry meaning that the performance metrics - such as `loss` - may be over inflated because for the test data the regression line would be very good at predicting a single combination of inputs' output values however on unseen data it may not perform as well due to over-representation of a single row within the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wineQualDf = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# run to set up the data frame to be pre-processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting NaN Values**\n",
    "\n",
    "The `countNaNRows()` takes in the data frame to be analysed and then uses the `df.isna()` function to create a dataframe of booleans identifiying whether the value at the corresponding location is a `NaN` value or not. Then the `.any(axis=1)` function is applied which conceptually flattens a dataframe into a list by looking at a row - determined by axis = 0 for columns or axis = 1 for rows - of a given index within the dataframe and then if any of the values in that row are `True` then the corresponding index in the created list will be `True` aswell, otherwise the corresponding index is set to `False`. This then means that the `.sum()` function can be applied as it is now operating on a list/array which takes `True = 1` and `False = 0` so by totalling the list it gives us the number of rows that contain `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(275)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countNaNRows(df):\n",
    "    NaNCount = df.isna().any(axis=1).sum()\n",
    "    return NaNCount\n",
    "\n",
    "\n",
    "countNaNRows(wineQualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting Outliers**\n",
    "\n",
    "When removing outliers, once abstracted, the larger problem isn't removing the values from the dataframe but identifying and establishing what constitutes an outlier.\n",
    "\n",
    "In the code snippet above an outlier is identified as a value that is either:\n",
    "- *greater than the third quartile of the dataset plus 3 × the interquartile range*\n",
    "- *less than the first quartile of the dataset minus 3 × the interquartile range*\n",
    "\n",
    "The function `countOutlierRows` counts the number of rows that would be removed due to containing values that would be classified as 'outliers' by the program, this is done by first getting the quantiles of the passed in dataframe and then calculates the interquartile range. Next it generates a boolean mask with values that meet either condition specified. It then calls the `.sum()` function to finally count the number of rows that would be removed from the data frame due to containing values that constitute outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(169)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countOutlierRows(df) -> pd.DataFrame:\n",
    "    quart1 = df.quantile(0.25)\n",
    "    quart3 = df.quantile(0.75)\n",
    "\n",
    "    IQrange = quart3 - quart1\n",
    "\n",
    "    lowerBound = quart1-3*IQrange\n",
    "    upperBound = quart3+3*IQrange\n",
    "\n",
    "    outlierCount = ((df<lowerBound) | (df>upperBound)).any(axis=1).sum()\n",
    "\n",
    "    return outlierCount\n",
    "\n",
    "\n",
    "countOutlierRows(wineQualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting the Number of Duplicate Rows**\n",
    "\n",
    "The function below - `countDuplicateRows` - counts the number of occurences of duplicate rows within the dataframe, this is done by using the inbuilt `.duplicated()` function that evaluates every row within a data frame to see if there has been an occurence of the same row before. This then returns a `series` that similarly to the `.any()` function has each element either evaluate to either `True` or `False` which - then again - can have the `.sum()` function applied to it which then essentially counts the number of occurences of `True` values which represnets the number of rows that are duplicated.\n",
    "\n",
    "So for example in the dataframe:\n",
    "    *'A': [1, 2, 3, 1, 2],*\n",
    "    *'B': ['a', 'b', 'c', 'a', 'b']*\n",
    "\n",
    "the output of the `countDuplicateRows()` would be 2 because there are 2 occurences of data duplication within the dataframe - `Row 4` is a duplicate of `Row 1` (1,a) and then `Row 5` is a copy of `Row 2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countDuplicateRows(df):\n",
    "    dupeCount = df.duplicated().sum()\n",
    "    return dupeCount\n",
    "\n",
    "countDuplicateRows(wineQualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1c <span style=\"color:red\">(20 marks)</span>\n",
    "**TASK**: Apply appropriate data preprocessing techniques to address the issues identified in Question 1b.\n",
    "- Provide a code solution that resolves the identified data issue(s).\n",
    "- Briefly explain the methods and parameters used in your solution. Ensure your explanation clearly justifies how these techniques improve data quality and suitability for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1c answer</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.105</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.083</td>\n",
       "      <td>15.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99570</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "31              6.9             0.685         0.00             2.5      0.105   \n",
       "32              8.3             0.655         0.12             2.3      0.083   \n",
       "34              5.2             0.320         0.25             1.8      0.103   \n",
       "36              7.8             0.600         0.14             2.4      0.086   \n",
       "37              8.1             0.380         0.28             2.1      0.066   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1593            6.8             0.620         0.08             1.9      0.068   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "31                   22.0                  37.0  0.99660  3.46       0.57   \n",
       "32                   15.0                 113.0  0.99660  3.17       0.66   \n",
       "34                   13.0                  50.0  0.99570  3.38       0.55   \n",
       "36                    3.0                  15.0  0.99750  3.42       0.60   \n",
       "37                   13.0                  30.0  0.99680  3.23       0.73   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1593                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "31       10.6     6.58  \n",
       "32        9.8     5.34  \n",
       "34        9.2     5.44  \n",
       "36       10.8     6.23  \n",
       "37        9.7     7.89  \n",
       "...       ...      ...  \n",
       "1593      9.5     6.03  \n",
       "1595     11.2     6.91  \n",
       "1596     11.0     6.99  \n",
       "1597     10.2     5.14  \n",
       "1598     11.0     6.97  \n",
       "\n",
       "[1190 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wineQualDf = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "\n",
    "class NaNhandling():\n",
    "    @staticmethod\n",
    "    def handleNaNmodal(df):\n",
    "        correctedDf = df.apply(lambda x: x.fillna(x.mode()[0],axis=0))\n",
    "        return correctedDf\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def handleNaNdrop(df):\n",
    "        return df.dropna()\n",
    "    \n",
    "    @staticmethod\n",
    "    def handleNaNValues(df):\n",
    "        handleMethod = 'drop'\n",
    "        \n",
    "        if countNaNRows(df) == 0:\n",
    "            return df\n",
    "        \n",
    "        if handleMethod == 'modal':\n",
    "            return NaNhandling.handleNaNmodal(df)\n",
    "\n",
    "        elif handleMethod == 'drop':\n",
    "            return NaNhandling.handleNaNdrop(df)\n",
    "        \n",
    "\n",
    "class outlierHandling():\n",
    "    @staticmethod\n",
    "    def getUpperLowerBounds(df):\n",
    "        rangeCoeff = 3\n",
    "        \n",
    "        quart1 = df.quantile(0.25)\n",
    "        quart3 = df.quantile(0.75)\n",
    "\n",
    "        IQrange = quart3 - quart1\n",
    "\n",
    "        lowerBound = quart1-rangeCoeff*IQrange\n",
    "        upperBound = quart3+rangeCoeff*IQrange      \n",
    "\n",
    "        return lowerBound,upperBound\n",
    "\n",
    "    @staticmethod\n",
    "    def handleOutliersModal(df):\n",
    "        \n",
    "        lowerBound,upperBound = outlierHandling.getUpperLowerBounds(df)\n",
    "    \n",
    "        for col in df.columns:\n",
    "            modalVal = df[col].mode()[0]\n",
    "            df[col] = df[col].apply(lambda x: modalVal if x<lowerBound[col] | x>upperBound[col] else x)\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def handleOutliersDrop(df):\n",
    "        lowerBound,upperBound = outlierHandling.getUpperLowerBounds(df)\n",
    "        strippedDf = df[~((df<lowerBound) | (df>upperBound)).any(axis=1)]\n",
    "        return strippedDf\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def handleOutliers(df):\n",
    "        handleMethod = 'drop'\n",
    "\n",
    "        if countDuplicateRows(df) == 0:\n",
    "            return df\n",
    "        \n",
    "        if handleMethod == 'modal':\n",
    "            return outlierHandling.handleOutliersModal(df)\n",
    "        \n",
    "        elif handleMethod == 'drop':\n",
    "            return outlierHandling.handleOutliersDrop(df)\n",
    "\n",
    "        \n",
    "def removeDuplicateRows(df):\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "\n",
    "def performPreProcessing(df):\n",
    "    df = NaNhandling.handleNaNValues(df)\n",
    "    df = outlierHandling.handleOutliers(df)\n",
    "    df = removeDuplicateRows(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "performPreProcessing(wineQualDf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "## Methods\n",
    "\n",
    "The large majority of **methods** within the snipped are contained within classes, this is because by encapsulating the methods within a class it can help improve readability and maintainability within the program as I - or anyone else - can easily see the overall operation - loosely shown by the class name - that the method aims to help be executed. Furthermore by containing related methods within classes it allows me to try and stick with the idea that each method/function should only do one thing, so if the methods weren't in classes then it would be a lot harder to figure out which functions call/are related to which other functions whereas classes provide us a way to 'group' similar functions.\n",
    "\n",
    "The idea of using classes solely for organisation - although they are typically used to reduce repeated code in a program in python and create objects - means that each function does not have a `self` argument as there is no need due to the only local variable being the dataframe (so an alternative method would be to create an instance of a `outlierHandling()` or `NaNHandling` and then pass in the dataframe that we want the operations to be applied to when the class is instantiated and then the operations could be performed by being called in the `__init__()` function - *this is shown in the first code snipped below* (Note this is isn't the most efficient/best structured approach) - and then returned at the end of the initial function call. In addition another solution could be to create a parent class that inherits the function of both `NaNhandling` and `outlierHandling` which would allow all pre-proccessing to be done in a single class - *shown in the second code snippet below*) which can be simply passed between the required methods. As there is no `self` attribute for either class each method is declared as a `@staticmethod` (this is not explicitly required but is good convention). \n",
    "\n",
    "There are 2 methods that are not contained within classes and this is because there is a very simple amount of code within each of them so there is no need to abstract sections of their code into other functions which could consititute using a class for orgnaisation, these 2 functions are:\n",
    "    - `removeDuplicateRows()`\n",
    "    - `performPreProcessing()`\n",
    "\n",
    "`removeDuplicateRows()` is just a single line that calls the built in pandas function `.drop_duplicates()` whose output is the returned straight away. Then `performPreProcessing()` conceptually acts as a handler as it allows us to call a single function that the 'branches' to 3 other functions which makes the code more readable and maintainable.\n",
    "\n",
    "### How it Improves Data Quality\n",
    "\n",
    "The methods and classes in the above code snippet help improve data quality through a variety of different ways as explained below:\n",
    "\n",
    "**1. Reduces Overfitting**\n",
    "\n",
    "if there are a large number of duplicate values within the dataset then the model will become more and more familiar with them and eventually will learn to predict the exact values of the inputs if the same combination of inputs and output are given multiple times, this means that the model will perform well on its training data as it essentially learns that in this dataset a some combination of inputs is always this output due to being seen multiple times rather than generating general trends based off of the the data - this is more apparent in more complex algorithms such as Neural Networks but still relevant - which is known as `overfitting`. \n",
    "\n",
    "So by removing duplicate rows from the dataset the percentage of unqiue rows in relation to the entire dataset increases which in turn means that the algorithm has to develop and identify more generalised trends rather than learning common values in the dataset, as a result this will improve the accuracy of predictions produced when the algorithm is provided un-seen data to analyse.\n",
    "\n",
    "**2. Prevents Crashing**\n",
    "\n",
    "In the original dataset there are a large number of `NaN` values this means that if the data was passed into an algorithm to be analysed then the program would either crash or throw an error and stop running. This could mean that the entire algorithm has to be trained again and although the current application is for linear regression on more complex types of machine learning having to re-train the network could take incredibly large amounts of time especially if the dataset is very large.\n",
    "\n",
    "Furthermore `NaN` values can create inconsistency within models, because if a model is trained on a dataset that has a large number of `NaN` values and those values are dropped or ignored, then when the same model is applied to a dataset that contains a lot fewer `NaN` values then the predictions/output of the data may be different to what is expected. This is why replacing the `NaN` values with the modal value for that column can be beneficial because instead of just losing the data for that row it maintains it. However this also presents its own issues as the model may receive incosistent data because if any `NaN` value in a column is set to that columns modal value then this could harm the linear relationship between the input attributes which inturn can make it harder for the model to learn. So each method of handling `Nan` values have their respective drawbacks.\n",
    "\n",
    "**3. Improves Prediction Accuracy**\n",
    "\n",
    "By removing rows that contain far outliers within the dataset it can help the regression model generalise better due to having more consistant data so especially with linear regression models as the algorithms is essentially trying to plot a line of best fit through the dataset if there are outlying pieces of data then the model may end up generating a skewed model as it tries to encompass the outliers as well as the general trend but this typically just results in an regression line that is slightly inaccurate for both typical data and the outliers. Therefore it is beneficial when generating a regression line to remove the outlying data values.  \n",
    "\n",
    "**4. Improves Vallidity of Performance Metrics**\n",
    "\n",
    "One of the most common performance metrics is `mean squared error` (mse), this metric works by squaring the error value so that large errors are penalised more than smaller error so helps detect if a model has a large deviations. However this also means that if outliers are not removed then when the model tries to predict it due to being an outlier the error should naturally be very large and therefore by squaring it the error only becomes much larger. \n",
    "\n",
    "This means although the model may currently be using appropritate weights for the general trend of data due to outliers it is getting heavily penalised and therefore can cause the model to skew as it believes its current weights produce inaccurate outputs. Therefore by removing large outliers it allows `mse` to provide a more accurate metric as it isn't being skewed by outliers.\n",
    "\n",
    "\n",
    "## Parameters\n",
    "\n",
    "**1.** `handleMethod`\n",
    "\n",
    "`handleMethod` provides a way for the programmer to be able to change how certain values are handled allowing a choice between `drop` and `modal`. This parameter decides how whether the program handles `outliers` and `NaN values` are changed within the data set.\n",
    "\n",
    "If **drop** is chosen then any rows containing outlying values are dropped from the data set and similarly in `NaNhandling()` if **drop** is selected then rows containing `NaN values` are dropped from the dataset whereas if **modal** is selected then the values are replaced by the modal value of their column.\n",
    "\n",
    "**2.** `upperBound` & `lowerBound`\n",
    "\n",
    "These 2 paramaters are the bounds that values must outside of to constitute outliers. The magnitude of the bounds can be changed by adjust how the scale of the `interquartile range` that is either added (`upperBound`) or subtracted (`lowerBound`). \n",
    "\n",
    "The way these are calculate is by first taking the 1st and 3rd quartile of the dataframe and then assigning those values to `quart1` and `quart3` respectively, then the difference between these is calculated and assigned to `IQrange`, once this value has been calculated it is then scaled (currently by 3x) and subtracted or added to `quart1` and `quart3` respectively to then create the 'threshold' values that constitute the `lowerBound` and `upperBound`.\n",
    "\n",
    "This helps improve data quality as it removes values that sit far away from the rough/general data pattern, however if the bounds are set too close together then values that are not actually meant to be outliers will be identified as outliers and hence removed from the dataset, this in turn means that the relationship between inputs and output will be very restricted and can cause the algorithm to over fit to the dataset as only values that roughly match a certain relationship will be kept. So as a result the regression line may provide strong performance metrics on the training data however on unseen data (due to not being able to properly generalise the relationship beause of data being restricted effectively to a certain relationship) it could be incredibly inaccurate as the unseen data doesn't specifically match the same trend that the training data did.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.105</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.083</td>\n",
       "      <td>15.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99570</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "31              6.9             0.685         0.00             2.5      0.105   \n",
       "32              8.3             0.655         0.12             2.3      0.083   \n",
       "34              5.2             0.320         0.25             1.8      0.103   \n",
       "36              7.8             0.600         0.14             2.4      0.086   \n",
       "37              8.1             0.380         0.28             2.1      0.066   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1593            6.8             0.620         0.08             1.9      0.068   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "31                   22.0                  37.0  0.99660  3.46       0.57   \n",
       "32                   15.0                 113.0  0.99660  3.17       0.66   \n",
       "34                   13.0                  50.0  0.99570  3.38       0.55   \n",
       "36                    3.0                  15.0  0.99750  3.42       0.60   \n",
       "37                   13.0                  30.0  0.99680  3.23       0.73   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1593                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "31       10.6     6.58  \n",
       "32        9.8     5.34  \n",
       "34        9.2     5.44  \n",
       "36       10.8     6.23  \n",
       "37        9.7     7.89  \n",
       "...       ...      ...  \n",
       "1593      9.5     6.03  \n",
       "1595     11.2     6.91  \n",
       "1596     11.0     6.99  \n",
       "1597     10.2     5.14  \n",
       "1598     11.0     6.97  \n",
       "\n",
       "[1190 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wineQualDf = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "\n",
    "class NaNhandling:\n",
    "    def __init__(self,df) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    def handleNaNmodal(self):\n",
    "        self.df = self.df.apply(lambda x: x.fillna(x.mode()[0], axis=0))\n",
    "\n",
    "    def handleNaNdrop(self):\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "    def handleNaNValues(self):\n",
    "        handleMethod = 'drop'\n",
    "\n",
    "        if countNaNRows(self.df) == 0:\n",
    "            return \n",
    "\n",
    "        if handleMethod == 'modal':\n",
    "            self.handleNaNmodal()\n",
    "        \n",
    "        elif handleMethod == 'drop':\n",
    "            self.handleNaNdrop()\n",
    "\n",
    "    def getDf(self):\n",
    "        return self.df\n",
    "\n",
    "\n",
    "class outlierHandling:\n",
    "    def __init__(self,df) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    def getUpperLowerBounds(self):\n",
    "        rangeCoef = 1\n",
    "\n",
    "        quart1 = self.df.quantile(0.25)\n",
    "        quart3 = self.df.quantile(0.75)\n",
    "\n",
    "        IQrange = quart3 - quart1\n",
    "        \n",
    "        lowerBound = quart1-rangeCoef*IQrange\n",
    "        upperBound = quart3+rangeCoef*IQrange\n",
    "        \n",
    "        return lowerBound, upperBound\n",
    "\n",
    "    def handleOutliersModal(self):\n",
    "        lowerBound, upperBound = self.getUpperLowerBounds()\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            modalVal = self.df[col].mode()[0]\n",
    "            self.df[col] = self.df[col].apply(lambda x: modalVal if (x < lowerBound[col] or x > upperBound[col]) else x)\n",
    "\n",
    "    def handleOutliersDrop(self):\n",
    "        lowerBound, upperBound = self.getUpperLowerBounds()\n",
    "        self.df = self.df[~((self.df < lowerBound) | (self.df > upperBound)).any(axis=1)]\n",
    "\n",
    "    def handleOutliers(self):\n",
    "        handleMethod = 'drop'\n",
    "\n",
    "        if countDuplicateRows(self.df) == 0:\n",
    "            return \n",
    "\n",
    "        if handleMethod == 'modal':\n",
    "            self.handleOutliersModal()\n",
    "\n",
    "\n",
    "        elif handleMethod == 'drop':\n",
    "            self.handleOutliersDrop()\n",
    "        \n",
    "    def getDf(self):\n",
    "        return self.df\n",
    "\n",
    "\n",
    "def performPreProcessing(df):\n",
    "    wineNaNhandler = NaNhandling(df)\n",
    "    wineNaNhandler.handleNaNValues()\n",
    "    df = wineNaNhandler.getDf() \n",
    "\n",
    "    wineOutlierHandler = outlierHandling(df)\n",
    "    wineOutlierHandler.handleOutliers()\n",
    "    df = wineOutlierHandler.getDf() \n",
    "\n",
    "    df = removeDuplicateRows(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def removeDuplicateRows(df):\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "\n",
    "performPreProcessing(wineQualDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.105</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.083</td>\n",
       "      <td>15.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99570</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "31              6.9             0.685         0.00             2.5      0.105   \n",
       "32              8.3             0.655         0.12             2.3      0.083   \n",
       "34              5.2             0.320         0.25             1.8      0.103   \n",
       "36              7.8             0.600         0.14             2.4      0.086   \n",
       "37              8.1             0.380         0.28             2.1      0.066   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1593            6.8             0.620         0.08             1.9      0.068   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "31                   22.0                  37.0  0.99660  3.46       0.57   \n",
       "32                   15.0                 113.0  0.99660  3.17       0.66   \n",
       "34                   13.0                  50.0  0.99570  3.38       0.55   \n",
       "36                    3.0                  15.0  0.99750  3.42       0.60   \n",
       "37                   13.0                  30.0  0.99680  3.23       0.73   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1593                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "31       10.6     6.58  \n",
       "32        9.8     5.34  \n",
       "34        9.2     5.44  \n",
       "36       10.8     6.23  \n",
       "37        9.7     7.89  \n",
       "...       ...      ...  \n",
       "1593      9.5     6.03  \n",
       "1595     11.2     6.91  \n",
       "1596     11.0     6.99  \n",
       "1597     10.2     5.14  \n",
       "1598     11.0     6.97  \n",
       "\n",
       "[1218 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wineQualDf = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "class NaNhandling:\n",
    "    def handleNaNmodal(self, df):\n",
    "        return df.apply(lambda x: x.fillna(x.mode()[0], axis=0))\n",
    "\n",
    "    def handleNaNdrop(self, df):\n",
    "        return df.dropna()\n",
    "\n",
    "    def handleNaNValues(self, df):\n",
    "        handleMethod = 'drop'\n",
    "\n",
    "        if countNaNRows(df) == 0:\n",
    "            return df\n",
    "\n",
    "        if handleMethod == 'modal':\n",
    "            return self.handleNaNmodal(df)\n",
    "        elif handleMethod == 'drop':\n",
    "            return self.handleNaNdrop(df)\n",
    "\n",
    "class outlierHandling:\n",
    "    def getUpperLowerBounds(self, df):\n",
    "        rangeCoeff = 4\n",
    "        \n",
    "        quart1 = df.quantile(0.25)\n",
    "        quart3 = df.quantile(0.75)\n",
    "\n",
    "        IQrange = quart3 - quart1\n",
    "        \n",
    "        lowerBound = quart1-rangeCoeff*IQrange\n",
    "        upperBound = quart3+rangeCoeff*IQrange\n",
    "        \n",
    "        return lowerBound, upperBound\n",
    "\n",
    "    def handleOutliersModal(self, df):\n",
    "        lowerBound, upperBound = self.getUpperLowerBounds(df)\n",
    "\n",
    "        for col in df.columns:\n",
    "            modalVal = df[col].mode()[0]\n",
    "            df[col] = df[col].apply(lambda x: modalVal if (x < lowerBound[col] or x > upperBound[col]) else x)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def handleOutliersDrop(self, df):\n",
    "        lowerBound, upperBound = self.getUpperLowerBounds(df)\n",
    "        return df[~((df < lowerBound) | (df > upperBound)).any(axis=1)]\n",
    "\n",
    "    def handleOutliers(self, df):\n",
    "        handleMethod = 'drop'\n",
    "\n",
    "        if countDuplicateRows(df) == 0:\n",
    "            return df\n",
    "\n",
    "        if handleMethod == 'modal':\n",
    "            return self.handleOutliersModal(df)\n",
    "\n",
    "\n",
    "        elif handleMethod == 'drop':\n",
    "            return self.handleOutliersDrop(df)\n",
    "\n",
    "class preProcessing(NaNhandling, outlierHandling):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.performPreProcessing()\n",
    "\n",
    "\n",
    "    def performPreProcessing(self):\n",
    "        self.df = self.handleNaNValues(self.df)\n",
    "        self.df = self.handleOutliers(self.df)\n",
    "        self.df = self.removeDuplicateRows()\n",
    "\n",
    "    def removeDuplicateRows(self):\n",
    "        return self.df.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "wineQualDf = preProcessing(wineQualDf).df\n",
    "wineQualDf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1d <span style=\"color:red\">(10 marks)</span>\n",
    "\n",
    "**TASK**: Train and evaluate a Linear Regression model using the preprocessed dataset.   \n",
    "- Print the model's weights.  \n",
    "- Print the model's accuracy. \n",
    "    - Evaluate the model using at least three different metrics.\n",
    "    - Briefly discuss the advantages of each metric in assessing model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1d answer</b>: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "`Mean Sqaured Error` is a metric that takes the error and then sqaures it meaning that largeer errors and emphasised and hence penalised more, this is good for models like `linear regression` as it places and emphasis on the algorithm generalising the data to produce a trend as due to the nature of how the metric is calculated high variance in the data is penalised more so therefore beneficial when using `linear regression` as it is essentially aiming to produce a line of best fit.\n",
    "\n",
    "However `MSE` may not always be the best metric unless outliers are appropriately removed from the data set - in this sense we can almost see the `rangeCoeff` variable above as 'controlling' the `MSE` by being almost directly proportional - *as shown in the graph generated by the first code snippet below* - so as the range of data values increases - `rangeCoeff` increasing - then `MSE` of the model also increases.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "`Mean Absolute Error` is the absolute value of the error value between the predicted and expected outputs from the data, this makes it very easy to understand and interpret because it is in the same units as the output data and because to calculate it you simply take the absolute value of the difference between every prediction and its corresponding expected output (error value) and then average those values.\n",
    "\n",
    "However like `MSE` `MAE` can also be manipulated by restricting data - in reality all error metrics can be manipulated like this - although there are other drawbacks such as the fact that `MAE` doesn't penalise large error values like `MAE` might which can mean it takes longer to train a model using `MAE`. The idea of it being 'less sensitive' can be seen on the graph generated by the code snipped below as the line of best fit for `MAE` doesn't have as much variance as the line of best fit or the scatter points for `MSE`.\n",
    "\n",
    "### R-Sqaured Score (R2)\n",
    "\n",
    "The `R2` error metric is useful for analyzing the quality of a model because - instead of focusing solely on the size of prediction errors - it looks at how well the model captures the variance in the dataset. More specifically `R2` measures how much of the total spread in the *dependent variable* - `wine quality` - can be explained by the *independent variables*  - input parameters - through the regression model. A **higher** `R2` value indicates that the model has captured a more accurate function that represents the trend/relationship between inputs and outputs, leading to more accurate predictions. In essence, `R2` evaluates the function the model has created to represent the data rather than just comparing the difference between the predicted and the expected outputs from the linear regression model.\n",
    "\n",
    "This is particularly beneficial for linear regression becase linear regression aims to create the best possible linear representation/function of the relationship, an error metric like `R2`, which assesses how well this function explains the data’s variance, is more informative than metrics that focus only on raw prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "maeValues = [\n",
    "            0.524150503696459, 0.489633766816119, 0.518911701329708, 0.542513367735157, 0.528600529889104, 0.529062954090948, 0.548515605563439, 0.562368377596734, 0.549700151331075, 0.548945122679055, 0.536109618132863, 0.582611027247426, 0.522892315880538, 0.564171827442956, 0.528083907542125, 0.520728538568393,\n",
    "            0.559331602420704, 0.500125433059847, 0.55744211566065, 0.548062550851324, 0.551646019500682, 0.552516769640311, 0.550048483597795, 0.55333412122424, 0.574298453379974, 0.537803261470552, 0.556004018935538, 0.556004018935538, 0.573628972959989, 0.573628972959989, 0.571531839262969, 0.57333280516338,\n",
    "            0.561967070791219, 0.565564503779835, 0.565996821470315, 0.565996821470315, 0.552225523307382, 0.552225523307382, 0.546709426123357, 0.570038870116688, 0.559228664029107, 0.559228664029107, 0.542121777214624, 0.542886601684819, 0.542886601684819, 0.52883277438753, 0.52883277438753, 0.547451616534304,\n",
    "            0.553275919885374, 0.55466168706618, 0.55466168706618, 0.55466168706618, 0.565978264824766, 0.564291179695381, 0.564291179695381, 0.564291179695381, 0.575395848994326, 0.575395848994326, 0.597787916551283, 0.597787916551283, 0.545869735578612, 0.545869735578612, 0.545869735578612, 0.534214806905159,\n",
    "            0.534214806905159, 0.573500185971709, 0.576213806634633, 0.583888541530576, 0.583888541530576, 0.56427886659331, 0.579399348014833, 0.579399348014833, 0.559526037634117, 0.559526037634117, 0.559526037634117, 0.559526037634117, 0.577266879742262, 0.552989918761829, 0.552989918761829, 0.550436182505199,\n",
    "            0.531151171094368, 0.531151171094368, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673, 0.543847344585673,\n",
    "            0.543847344585673, 0.543847344585673, 0.546586610382363, 0.546586610382363, 0.546586610382363, 0.546586610382363, 0.546586610382363, 0.546586610382363, 0.546586610382363, 0.546586610382363, 0.553440414914657, 0.553440414914657, 0.553440414914657, 0.553440414914657, 0.581213307553105, 0.562924214793546,\n",
    "            0.562924214793546, 0.562924214793546, 0.568671981533758, 0.568671981533758, 0.568671981533758, 0.574479545296983, 0.574479545296983, 0.562333621151065, 0.562333621151065, 0.562333621151065, 0.562333621151065, 0.562333621151065, 0.571981945899205, 0.56705318592999, 0.56705318592999, 0.56705318592999,\n",
    "            0.56705318592999, 0.56705318592999, 0.555369285047028, 0.555369285047028, 0.555369285047028, 0.555369285047028, 0.555369285047028, 0.555369285047028, 0.555369285047028, 0.555369285047028, 0.580250532606646, 0.571616998304226\n",
    "            ]\n",
    "\n",
    "mseValues = [\n",
    "            0.41137291812213, 0.37252458703163, 0.422832662199773, 0.475922534082106, 0.43344716853946, 0.429803742508529, 0.45139601233721, 0.487774853566588, 0.466975872631439, 0.479908915844617, 0.46207722494521, 0.5404146359066, 0.424704543900385, 0.484836670006687, 0.443111504411245, 0.41335154212612,\n",
    "            0.486225910904466, 0.404780758661673, 0.493181769505738, 0.45436003990284, 0.510866918308688, 0.495544328185175, 0.495228043347772, 0.495686767358729, 0.5233130822426, 0.474092304812014, 0.497019927253871, 0.497019927253871, 0.537334068998705, 0.537334068998705, 0.531486328377593, 0.536086680162506,\n",
    "            0.533830564808525, 0.493992682001025, 0.518474470091756, 0.518474470091756, 0.487187615680335, 0.487187615680335, 0.504390321297637, 0.534583526191777, 0.507767713366949, 0.507767713366949, 0.487932860211316, 0.490982515890239, 0.490982515890239, 0.429210785203891, 0.429210785203891, 0.48827177115629,\n",
    "            0.508844729714666, 0.497209796897211, 0.497209796897211, 0.497209796897211, 0.502626535008578, 0.507244355043965, 0.507244355043965, 0.507244355043965, 0.524555874995689, 0.524555874995689, 0.560387699845408, 0.560387699845408, 0.496317317784669, 0.496317317784669, 0.496317317784669, 0.467881733368297,\n",
    "            0.467881733368297, 0.532148098160305, 0.552847402247199, 0.555998806427656, 0.555998806427656, 0.526751371557955, 0.553015259505667, 0.553015259505667, 0.508123898280162, 0.508123898280162, 0.508123898280162, 0.508123898280162, 0.52675854343626, 0.504435480499154, 0.504435480499154, 0.506369711156497,\n",
    "            0.467684870759237, 0.467684870759237, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673, 0.494663010231673,\n",
    "            0.494663010231673, 0.494663010231673, 0.51241950116992, 0.51241950116992, 0.51241950116992, 0.51241950116992, 0.51241950116992, 0.51241950116992, 0.51241950116992, 0.51241950116992, 0.471545352123161, 0.471545352123161, 0.471545352123161, 0.471545352123161, 0.536758218940164, 0.580186038790983,\n",
    "            0.580186038790983, 0.580186038790983, 0.515069233182162, 0.515069233182162, 0.515069233182162, 0.528309809937177, 0.528309809937177, 0.535356681751138, 0.535356681751138, 0.535356681751138, 0.535356681751138, 0.535356681751138, 0.537946373493535, 0.539564536757469, 0.539564536757469, 0.539564536757469,\n",
    "            0.539564536757469, 0.539564536757469, 0.509949109063696, 0.509949109063696, 0.509949109063696, 0.509949109063696, 0.509949109063696, 0.509949109063696, 0.509949109063696, 0.509949109063696, 0.576746163435011, 0.561486041592107\n",
    "            ]\n",
    "\n",
    "rSqauredValues = [\n",
    "            0.172474243064331, 0.286986116766961, 0.275100201700508, 0.261219070082639, 0.306113089714964, 0.286913983260071, 0.342421045990775, 0.340665129378254, 0.344820050030403, 0.328516465717167, 0.360717966661289, 0.321531720880443, 0.300304038707461, 0.337998872993202, 0.361841652930054, 0.375228698866787,\n",
    "            0.307290270392232, 0.367147143884927, 0.243975661260013, 0.252107502711714, 0.244054265878086, 0.267596117278222, 0.322041224683881, 0.298406407403633, 0.276515539396682, 0.275802118876792, 0.296475191585246, 0.296475191585246, 0.246361571159293, 0.246361571159293, 0.293296891072954, 0.301043269245308,\n",
    "            0.330186676319883, 0.310442730243074, 0.347547285739785, 0.347547285739785, 0.357706385289492, 0.357706385289492, 0.285581873968446, 0.287537150107022, 0.316923336719711, 0.316923336719711, 0.311235552764871, 0.327337542394256, 0.327337542394256, 0.26165468877668, 0.26165468877668, 0.240809833974434,\n",
    "            0.30385606506618, 0.306443064835034, 0.306443064835034, 0.306443064835034, 0.35044837898248, 0.347014088138702, 0.347014088138702, 0.347014088138702, 0.314369482909165, 0.314369482909165, 0.283290549063792, 0.283290549063792, 0.29323303695673, 0.29323303695673, 0.29323303695673, 0.300581455525876,\n",
    "            0.300581455525876, 0.25005414912039, 0.27611788843646, 0.277146292020069, 0.277146292020069, 0.309254821521668, 0.269265995714055, 0.269265995714055, 0.332171161214552, 0.332171161214552, 0.332171161214552, 0.332171161214552, 0.283249502087392, 0.326870230631475, 0.326870230631475, 0.347801878141868,\n",
    "            0.359436985271384, 0.359436985271384, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596, 0.332777541998596,\n",
    "            0.332777541998596, 0.332777541998596, 0.32528541701469, 0.32528541701469, 0.32528541701469, 0.32528541701469, 0.32528541701469, 0.32528541701469, 0.32528541701469, 0.32528541701469, 0.340990077894418, 0.340990077894418, 0.340990077894418, 0.340990077894418, 0.242093745450799, 0.265678804910122,\n",
    "            0.265678804910122, 0.265678804910122, 0.290175972793924, 0.290175972793924, 0.290175972793924, 0.256373219574212, 0.256373219574212, 0.276591907294662, 0.276591907294662, 0.276591907294662, 0.276591907294662, 0.276591907294662, 0.28040688045226, 0.218323887566102, 0.218323887566102, 0.218323887566102,\n",
    "            0.218323887566102, 0.218323887566102, 0.279748596776056, 0.279748596776056, 0.279748596776056, 0.279748596776056, 0.279748596776056, 0.279748596776056, 0.279748596776056, 0.279748596776056, 0.242817074450117, 0.231560897747874\n",
    "            ]\n",
    "\n",
    "def plotLoBF(rangeCoeffsToCheck,data,color): \n",
    "    coefficients = np.polyfit(rangeCoeffsToCheck,data,3)\n",
    "    polynomial = np.poly1d(coefficients)\n",
    "    xfit = np.linspace(rangeCoeffsToCheck.min(),rangeCoeffsToCheck.max(),100)\n",
    "    yfit = polynomial(xfit)\n",
    "\n",
    "    plt.plot(xfit,yfit,color=color,alpha=1)\n",
    "\n",
    "def plotData():\n",
    "    rangeCoeffsToCheck = np.arange(1,15,0.1)\n",
    "    plt.scatter(rangeCoeffsToCheck,mseValues,marker = 'x',color='blue',alpha = 1,label = 'MSE Values')\n",
    "    plt.scatter(rangeCoeffsToCheck,maeValues,marker = 'x',color='red',alpha=1,label = 'MAE Values')\n",
    "    plt.scatter(rangeCoeffsToCheck,rSqauredValues,marker = 'x',color='orange',alpha=1,label='R^2 Values')\n",
    "    \n",
    "    plotLoBF(rangeCoeffsToCheck,mseValues,'blue')\n",
    "    plotLoBF(rangeCoeffsToCheck,maeValues,'red')\n",
    "    plotLoBF(rangeCoeffsToCheck,rSqauredValues,'orange')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context**\n",
    "\n",
    "*The above snippet uses data that I generated using a modified version of the linear regression algorithm combined with the pre-processing algorithm, then ran using a handler function so that i could repeatedly iterate over a list of `rangeCoeff` values and then get an associated `MAE`,`MSE` and `R Squared Score` for each range of acceptable data. This then provides me with enough data to be able to use numpy's buit-in `polyfit` function amongst others to generate a 3rd degree polynomial line of best fit representing the trend of each error value in relation to the range of acceptable data.*\n",
    "\n",
    "*Each error metric's line of best fit is the same colour as that of the plotted points for the metric - ie line of best fit for MSE values is Blue because MSE values are plotted in blue.*\n",
    "\n",
    "*This was mainly done to help illustrate the point of how all the error metrics can be somewhat manipulated in quite a simple way by just restricting the data so the regression line better fits the data. This was successfully shown on the graph as we can see that when a smaller range of data values are allowed then the lines begin to converge towards a single point with both `MSE` and `MAE` tending downards showing an averge decrease in the size of error and `R Squared` tends upwards as the model better explains variance within the dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Solution for Q1d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.53149\n",
      "mae: 0.57153\n",
      "Rsquared score: 0.2933\n",
      "\n",
      "Weights (coefficients) for each feature:\n",
      "fixed acidity: -0.88237\n",
      "volatile acidity: -1.29893\n",
      "citric acid: -0.37671\n",
      "residual sugar: -0.37132\n",
      "chlorides: -0.31211\n",
      "free sulfur dioxide: 0.21554\n",
      "total sulfur dioxide: -0.50172\n",
      "density: 0.80378\n",
      "pH: -1.73968\n",
      "sulphates: 1.51877\n",
      "alcohol: 1.85543\n",
      "Bias (intercept): 6.41784\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "plotRelationships = False\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X = wineQualDf.drop(columns=['quality'])\n",
    "y = wineQualDf[['quality']]\n",
    "\n",
    "XScaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(XScaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(Xtrain, ytrain)\n",
    "yPred = model.predict(Xtest)\n",
    "\n",
    "mse = mean_squared_error(ytest, yPred)\n",
    "mae = mean_absolute_error(ytest, yPred)\n",
    "r2 = r2_score(ytest, yPred)\n",
    "\n",
    "print(f'mse: {round(mse, 5)}')\n",
    "print(f'mae: {round(mae, 5)}')\n",
    "print(f'Rsquared score: {round(r2, 5)}')\n",
    "\n",
    "print(\"\\nWeights (coefficients) for each feature:\")\n",
    "for feature, weight in zip(X.columns, model.coef_[0]):\n",
    "    print(f\"{feature}: {round(weight, 5)}\")\n",
    "\n",
    "print(f\"Bias (intercept): {round(model.intercept_[0], 5)}\")\n",
    "\n",
    "if plotRelationships:\n",
    "    fig, axes = plt.subplots(len(X.columns), 1, figsize=(10, 5 * len(X.columns)))\n",
    "\n",
    "    for i, feature in enumerate(X.columns):\n",
    "        axes[i].scatter(wineQualDf[feature], wineQualDf[\"quality\"], alpha=0.5, color='blue',marker='x')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel(\"Quality\")\n",
    "        axes[i].set_title(f\"{feature} vs. Quality\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"text-align:left;\"><h2>Question 2. Prediction Model 2<span style=\"float:right;\">[20 marks]</span></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a <span style=\"color:red\">(10 marks)</span>\n",
    "\n",
    "**TASK**: Build a different machine learning model for the same prediction task.\n",
    "- Choose a model covered in the lectures or explain your choice of a different method. If you choose a different method, provide at at least two arguments to justify your choice compared to the ones covered in the lectures. \n",
    "- Specify which model you selected and why. \n",
    "- List the key parameters of your chosen model (Model 2).\n",
    "- Provide a code implementation for the selected method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q2a answer</b>:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choice\n",
    "I chose to use an **Artificial Neural Network** for a couple of reasons as shown below:\n",
    "\n",
    "**Non-Linear Relations**\n",
    "\n",
    "As `Linear Regression` suggests in the name it aims to plot a linear line that can predict for a given a set of inputs `x` you'll get a certain output `y`, however this assumes that the data is linearly related. In the **Wine Quality Dataset** it is unlikely that the relationships between each of the input features are linearly related, in reality their relationships are likely more complex than this. Therefore a `ANN` may be more appropriate because conceptually it does still plot a regression line but the line that it generates can be in as many dimensions as needed rather than just 2 dimensions meaning that it can map out much more complex relationships - such as that which might be seen in the **Wine Quality Dataset**\n",
    "\n",
    "Building upon this, certain features within the dataset may have an effect on other features within the input set, for example `Free Sulfur Dioxide`, `Total Sulphur Dioxide` and `Sulphates` are all inputs into the model however they also have a relationship within themseleves, this relationship might not get picked up by a simple model such as a Linear Regression model however an `ANN` is able to learn more complex relationships within the dataset provided and therefore might be able to more accurately predict `Wine Quality` as the network can now make use of relationships that weren't previously identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.read_csv('winequality-red.csv').columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - loss: 35.9421 - mae: 5.9192 - val_loss: 22.2869 - val_mae: 4.5675 - learning_rate: 0.0100\n",
      "Epoch 2/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 20.2921 - mae: 4.2925 - val_loss: 10.7995 - val_mae: 2.8088 - learning_rate: 0.0100\n",
      "Epoch 3/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 10.4117 - mae: 2.6660 - val_loss: 10.5895 - val_mae: 2.0474 - learning_rate: 0.0100\n",
      "Epoch 4/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 9.1084 - mae: 2.0197 - val_loss: 5.4547 - val_mae: 1.4832 - learning_rate: 0.0100\n",
      "Epoch 5/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 5.4388 - mae: 1.5876 - val_loss: 3.7422 - val_mae: 1.4807 - learning_rate: 0.0100\n",
      "Epoch 6/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3.8995 - mae: 1.5157 - val_loss: 4.5054 - val_mae: 1.7531 - learning_rate: 0.0100\n",
      "Epoch 7/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 4.3362 - mae: 1.7015 - val_loss: 4.5557 - val_mae: 1.7582 - learning_rate: 0.0100\n",
      "Epoch 8/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.2311 - mae: 1.6813 - val_loss: 3.7778 - val_mae: 1.5628 - learning_rate: 0.0100\n",
      "Epoch 9/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3.7002 - mae: 1.5267 - val_loss: 3.0993 - val_mae: 1.3684 - learning_rate: 0.0100\n",
      "Epoch 10/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.1086 - mae: 1.3431 - val_loss: 2.7053 - val_mae: 1.2503 - learning_rate: 0.0100\n",
      "Epoch 11/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.7357 - mae: 1.2593 - val_loss: 2.3961 - val_mae: 1.1831 - learning_rate: 0.0100\n",
      "Epoch 12/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2.5420 - mae: 1.2128 - val_loss: 2.2869 - val_mae: 1.1715 - learning_rate: 0.0100\n",
      "Epoch 13/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 2.3965 - mae: 1.2430 - val_loss: 2.2341 - val_mae: 1.1696 - learning_rate: 0.0100\n",
      "Epoch 14/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 2.2829 - mae: 1.1946 - val_loss: 2.0450 - val_mae: 1.1153 - learning_rate: 0.0100\n",
      "Epoch 15/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.9238 - mae: 1.0965 - val_loss: 1.7807 - val_mae: 1.0291 - learning_rate: 0.0100\n",
      "Epoch 16/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.6969 - mae: 1.0455 - val_loss: 1.6532 - val_mae: 0.9817 - learning_rate: 0.0100\n",
      "Epoch 17/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1.6561 - mae: 1.0169 - val_loss: 1.6284 - val_mae: 0.9807 - learning_rate: 0.0100\n",
      "Epoch 18/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.7367 - mae: 1.0184 - val_loss: 1.5737 - val_mae: 0.9795 - learning_rate: 0.0100\n",
      "Epoch 19/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.5238 - mae: 0.9678 - val_loss: 1.5500 - val_mae: 0.9881 - learning_rate: 0.0100\n",
      "Epoch 20/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.4952 - mae: 0.9756 - val_loss: 1.4890 - val_mae: 0.9699 - learning_rate: 0.0100\n",
      "Epoch 21/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.3980 - mae: 0.9235 - val_loss: 1.3673 - val_mae: 0.9215 - learning_rate: 0.0100\n",
      "Epoch 22/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.3884 - mae: 0.9164 - val_loss: 1.2913 - val_mae: 0.8870 - learning_rate: 0.0100\n",
      "Epoch 23/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.2186 - mae: 0.8691 - val_loss: 1.2382 - val_mae: 0.8645 - learning_rate: 0.0100\n",
      "Epoch 24/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.1846 - mae: 0.8506 - val_loss: 1.1605 - val_mae: 0.8372 - learning_rate: 0.0100\n",
      "Epoch 25/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.1642 - mae: 0.8670 - val_loss: 1.0945 - val_mae: 0.8140 - learning_rate: 0.0100\n",
      "Epoch 26/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.1083 - mae: 0.8393 - val_loss: 1.0333 - val_mae: 0.7923 - learning_rate: 0.0100\n",
      "Epoch 27/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.0920 - mae: 0.8347 - val_loss: 0.9906 - val_mae: 0.7790 - learning_rate: 0.0100\n",
      "Epoch 28/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.9451 - mae: 0.7735 - val_loss: 0.9554 - val_mae: 0.7684 - learning_rate: 0.0100\n",
      "Epoch 29/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.9519 - mae: 0.7757 - val_loss: 0.9146 - val_mae: 0.7531 - learning_rate: 0.0100\n",
      "Epoch 30/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.8557 - mae: 0.7385 - val_loss: 0.8865 - val_mae: 0.7422 - learning_rate: 0.0100\n",
      "Epoch 31/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.8911 - mae: 0.7461 - val_loss: 0.8594 - val_mae: 0.7296 - learning_rate: 0.0100\n",
      "Epoch 32/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.8469 - mae: 0.7397 - val_loss: 0.8402 - val_mae: 0.7214 - learning_rate: 0.0100\n",
      "Epoch 33/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8529 - mae: 0.7308 - val_loss: 0.8222 - val_mae: 0.7159 - learning_rate: 0.0100\n",
      "Epoch 34/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.8322 - mae: 0.7285 - val_loss: 0.8013 - val_mae: 0.7078 - learning_rate: 0.0100\n",
      "Epoch 35/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7582 - mae: 0.6901 - val_loss: 0.7764 - val_mae: 0.6972 - learning_rate: 0.0100\n",
      "Epoch 36/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7675 - mae: 0.6982 - val_loss: 0.7497 - val_mae: 0.6854 - learning_rate: 0.0100\n",
      "Epoch 37/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7499 - mae: 0.7033 - val_loss: 0.7237 - val_mae: 0.6721 - learning_rate: 0.0100\n",
      "Epoch 38/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7337 - mae: 0.6782 - val_loss: 0.7030 - val_mae: 0.6617 - learning_rate: 0.0100\n",
      "Epoch 39/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.7033 - mae: 0.6616 - val_loss: 0.6888 - val_mae: 0.6559 - learning_rate: 0.0100\n",
      "Epoch 40/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.6688 - mae: 0.6557 - val_loss: 0.6786 - val_mae: 0.6536 - learning_rate: 0.0100\n",
      "Epoch 41/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.6455 - mae: 0.6484 - val_loss: 0.6735 - val_mae: 0.6524 - learning_rate: 0.0100\n",
      "Epoch 42/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6391 - mae: 0.6386 - val_loss: 0.6707 - val_mae: 0.6482 - learning_rate: 0.0100\n",
      "Epoch 43/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.6418 - mae: 0.6369 - val_loss: 0.6587 - val_mae: 0.6425 - learning_rate: 0.0100\n",
      "Epoch 44/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.6573 - mae: 0.6550 - val_loss: 0.6498 - val_mae: 0.6398 - learning_rate: 0.0100\n",
      "Epoch 45/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.6280 - mae: 0.6268 - val_loss: 0.6383 - val_mae: 0.6318 - learning_rate: 0.0100\n",
      "Epoch 46/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.6564 - mae: 0.6383 - val_loss: 0.6359 - val_mae: 0.6265 - learning_rate: 0.0100\n",
      "Epoch 47/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.6019 - mae: 0.6182 - val_loss: 0.6260 - val_mae: 0.6257 - learning_rate: 0.0100\n",
      "Epoch 48/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5949 - mae: 0.6109 - val_loss: 0.6185 - val_mae: 0.6215 - learning_rate: 0.0100\n",
      "Epoch 49/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6026 - mae: 0.6198 - val_loss: 0.6182 - val_mae: 0.6193 - learning_rate: 0.0100\n",
      "Epoch 50/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5462 - mae: 0.5908 - val_loss: 0.6109 - val_mae: 0.6175 - learning_rate: 0.0100\n",
      "Epoch 51/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5968 - mae: 0.6124 - val_loss: 0.5996 - val_mae: 0.6108 - learning_rate: 0.0100\n",
      "Epoch 52/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5663 - mae: 0.6027 - val_loss: 0.5937 - val_mae: 0.6059 - learning_rate: 0.0100\n",
      "Epoch 53/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5795 - mae: 0.6076 - val_loss: 0.5931 - val_mae: 0.6071 - learning_rate: 0.0100\n",
      "Epoch 54/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5707 - mae: 0.6000 - val_loss: 0.5954 - val_mae: 0.6080 - learning_rate: 0.0100\n",
      "Epoch 55/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5576 - mae: 0.5989 - val_loss: 0.5937 - val_mae: 0.6082 - learning_rate: 0.0100\n",
      "Epoch 56/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.5770 - mae: 0.6104 - val_loss: 0.5924 - val_mae: 0.6076 - learning_rate: 0.0100\n",
      "Epoch 57/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5666 - mae: 0.5956 - val_loss: 0.6067 - val_mae: 0.6087 - learning_rate: 0.0100\n",
      "Epoch 58/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5410 - mae: 0.5816 - val_loss: 0.5982 - val_mae: 0.6053 - learning_rate: 0.0050\n",
      "Epoch 59/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5657 - mae: 0.6013 - val_loss: 0.5909 - val_mae: 0.6095 - learning_rate: 0.0050\n",
      "Epoch 60/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5887 - mae: 0.6114 - val_loss: 0.5901 - val_mae: 0.6102 - learning_rate: 0.0050\n",
      "Epoch 61/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5438 - mae: 0.5866 - val_loss: 0.5844 - val_mae: 0.6012 - learning_rate: 0.0050\n",
      "Epoch 62/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5540 - mae: 0.5950 - val_loss: 0.5848 - val_mae: 0.6002 - learning_rate: 0.0050\n",
      "Epoch 63/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5410 - mae: 0.5860 - val_loss: 0.5813 - val_mae: 0.5996 - learning_rate: 0.0050\n",
      "Epoch 64/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.5531 - mae: 0.5927 - val_loss: 0.5812 - val_mae: 0.6026 - learning_rate: 0.0050\n",
      "Epoch 65/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5377 - mae: 0.5862 - val_loss: 0.5826 - val_mae: 0.6041 - learning_rate: 0.0050\n",
      "Epoch 66/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5357 - mae: 0.5778 - val_loss: 0.5803 - val_mae: 0.6007 - learning_rate: 0.0050\n",
      "Epoch 67/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5388 - mae: 0.5838 - val_loss: 0.5798 - val_mae: 0.5990 - learning_rate: 0.0050\n",
      "Epoch 68/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5353 - mae: 0.5868 - val_loss: 0.5795 - val_mae: 0.5986 - learning_rate: 0.0050\n",
      "Epoch 69/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5205 - mae: 0.5690 - val_loss: 0.5781 - val_mae: 0.6000 - learning_rate: 0.0050\n",
      "Epoch 70/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5220 - mae: 0.5778 - val_loss: 0.5783 - val_mae: 0.6008 - learning_rate: 0.0050\n",
      "Epoch 71/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5566 - mae: 0.5925 - val_loss: 0.5785 - val_mae: 0.5987 - learning_rate: 0.0050\n",
      "Epoch 72/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.5275 - mae: 0.5764 - val_loss: 0.5781 - val_mae: 0.5987 - learning_rate: 0.0050\n",
      "Epoch 73/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.5423 - mae: 0.5890 - val_loss: 0.5749 - val_mae: 0.5993 - learning_rate: 0.0050\n",
      "Epoch 74/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5312 - mae: 0.5821 - val_loss: 0.5727 - val_mae: 0.5979 - learning_rate: 0.0025\n",
      "Epoch 75/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5233 - mae: 0.5708 - val_loss: 0.5707 - val_mae: 0.5963 - learning_rate: 0.0025\n",
      "Epoch 76/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.5132 - mae: 0.5695 - val_loss: 0.5711 - val_mae: 0.5953 - learning_rate: 0.0025\n",
      "Epoch 77/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5497 - mae: 0.5778 - val_loss: 0.5696 - val_mae: 0.5952 - learning_rate: 0.0025\n",
      "Epoch 78/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5547 - mae: 0.5925 - val_loss: 0.5692 - val_mae: 0.5964 - learning_rate: 0.0025\n",
      "Epoch 79/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5145 - mae: 0.5704 - val_loss: 0.5695 - val_mae: 0.5976 - learning_rate: 0.0025\n",
      "Epoch 80/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5106 - mae: 0.5602 - val_loss: 0.5702 - val_mae: 0.5974 - learning_rate: 0.0025\n",
      "Epoch 81/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5146 - mae: 0.5611 - val_loss: 0.5709 - val_mae: 0.5967 - learning_rate: 0.0025\n",
      "Epoch 82/128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5101 - mae: 0.5636 - val_loss: 0.5715 - val_mae: 0.5968 - learning_rate: 0.0025\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import Sequential,layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential([\n",
    "        layers.Input(shape=(11,)),\n",
    "        layers.Dense(32,activation='relu'),\n",
    "\n",
    "        layers.Dense(64,activation='relu'),\n",
    "        layers.Dropout(rate=0.1),\n",
    "\n",
    "        layers.Dense(32,activation='relu'),\n",
    "    \n",
    "        layers.Dense(1,activation='linear')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "def trainNeuralNetwork(trainingDataFrame):\n",
    "    model = createModel()\n",
    "    optimiser = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimiser,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    earlyStopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_mae',\n",
    "        patience = 20,\n",
    "        min_delta = 0.01,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    reduceLearningRate = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_mae',\n",
    "        factor=0.5,\n",
    "        patience = 5,\n",
    "        min_lr = 1e-6\n",
    "    )\n",
    "\n",
    "    checkPointCallback = keras.callbacks.ModelCheckpoint(\n",
    "        'model_checkpoint.keras',\n",
    "        save_best_only = True,\n",
    "        monitor = 'val_mae',\n",
    "        mode = 'min',\n",
    "    )\n",
    "\n",
    "    trainingDataFrame = trainingDataFrame.dropna()\n",
    "    X = trainingDataFrame.drop(columns=['quality']).values\n",
    "    y = trainingDataFrame['quality'].values\n",
    "\n",
    "    Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "    Xtrain = scaler.fit_transform(Xtrain)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "\n",
    "    history = model.fit(\n",
    "        Xtrain,ytrain,\n",
    "        validation_data=(Xtest,ytest),\n",
    "        batch_size=512,\n",
    "        epochs = 128,\n",
    "        callbacks=[earlyStopping,reduceLearningRate,checkPointCallback],\n",
    "    )\n",
    "\n",
    "    historydf = pd.DataFrame(history.history)\n",
    "    historydf.loc[:,['mae','val_mae']].plot(title = 'MAE for red wine quality prediction training')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainingDataFrame = pd.read_csv('winequality-red.csv')\n",
    "    trainNeuralNetwork(trainingDataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b <span style=\"color:red\">(10 marks)</span>\n",
    "**TASK**: Evaluate the performance of your new model and compare it to Prediction Model 1.\n",
    "- Analyze whether the new model performs better or worse and explain why.\n",
    "    - Base your evaluation on the same metrics used in Question 1d).\n",
    "- Include one plot visually comparing the performance of both models.\n",
    "- Provide a brief textual explanation interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q2b answer</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"text-align:left;\"><h2>Question 3. Comparison and Improvement<span style=\"float:right;\">[30 marks]</span></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Question 3a <span style=\"color:red\">(15 marks)</span>\n",
    "**TASK**: Analyze the impact of removing the least important feature from Prediction Model 1.\n",
    "- Identify and remove the least important feature. \n",
    "- Retrain the Linear Regression model and evaluate its performance. \n",
    "- Compare the results before and after feature removal.\n",
    "- Provide a code implementation and a justification explaining the impact on model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3a answer</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b <span style=\"color:red\">(15 marks)</span>\n",
    "**TASK**: Based on your observations, suggest strategies for improving future models when predicting on new data.\n",
    "- Discuss potential improvements. \n",
    "\n",
    "<b>Hint</b>: based on relevant analysis, feature selection, feature scaling and data processing (e.g. resolve imbalanced samples, errors and outliers, etc.) could all potentially improve the model by reducing training time, fixing overfitting and improving interpretability, etc. \n",
    "You can also explore external resources for other potential approaches or techniques.<br>\n",
    "\n",
    "<b>Note</b>: Coding is optional here, but your answers should be supported by relevant analysis or justifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3b answer</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix. Coursework Instructions\n",
    "\n",
    "<b>Coursework Support</b>:\n",
    "- COMP1008 computing tutorials and exercises on data processing and machine learning models on different example problems\n",
    "- Example code building and analysing machine learning models in COMP1008 lectures slides on 'Machine learning'\n",
    "- In the computing sessions, Q&A support for developing .ipynb projects\n",
    "- In Teams channel 'COMP1008 2024/25 / Questions': support of common questions\n",
    "\n",
    "<b>Marks</b>: in total 100 marks (count for 25% in COMP1008), awarded on the basis of:\n",
    "- knowledge and understanding on the theories covered in lectures when answering the questions in the Jupyter Notebook report\n",
    "- how informative and well presented your code, visualisations and results are (e.g. necessary labels in plots)\n",
    "- self-learning ability making use of tutorial materials and online resources\n",
    "- problem solving skills to obtain the answers and results for the specific dataset\n",
    "- concise report with key details, e.g. parameters, data, etc. for others to repeat your methods and obtain the same results.\n",
    "\n",
    "For more information of COMP1008 assessment please refer to the coursework issue in Moodle ('Course Content / Assessment')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Format</b>:\n",
    "- One single .ipynb file named 202425_COMP1008_cw_XXX.ipynb, where XXX is your username (e.g. psxyz)\n",
    "- The .ipynb file should include your code and answers, using this given .ipynb template (please add cells as needed)\n",
    "- You could use additional Python libraries as you wish, in addition to the ones demonstrated in the computing sessions\n",
    "- There are multiple ways using different methods to complete the tasks. These are fine as long as all answers and analysis are supported by the code implemented in Jupyter Notebook, not by using other means (e.g. operations in Excel, or by using other languages, etc.).\n",
    "\n",
    "<b>Submission</b>: \n",
    "- Deadline: <b><font color = \"red\">24 March, 3pm</font></b>.\n",
    "- Late submission leads to a 5% deduction of the coursework on each weekday. Work submitted one week late will receive a 0 for the coursework.\n",
    "- Method: in Moodle submit a single .ipynb file named 202425_COMP1008_cw_XXX.ipynb\n",
    "- If you can’t submit your coursework on time due to ECs, please contact Student Services and your personal tutor ASAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<b>Note: Plagiarism vs. Group Discussions</b> \n",
    "\n",
    "As you should know, plagiarism is completely unacceptable and will be dealt with according to University's standard policies.<br>\n",
    "Students are encouraged to have only general discussions on the theory (not the specific questions) when completing the coursework.<br>\n",
    "It is important that when you actually do your coursework and write the answers, you do it individually.<br>\n",
    "Do NOT, under any circumstances, share your report, code or figures, etc. with anyone else."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
