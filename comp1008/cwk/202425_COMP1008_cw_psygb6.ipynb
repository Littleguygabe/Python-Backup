{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP1008 2024/25 Coursework - Wine Quality Prediction with Machine Learning\n",
    "\n",
    "#### **Student Name**: Gabriel Bridger\n",
    "#### **Student ID**: 2086810 \n",
    "\n",
    "## Task description\n",
    "\n",
    "**Main Task**: Utilizing the provided Red Wine Quality dataset, build a Linear Regression Model and another Machine Learning Model of your choice to predict wine quality. Employ appropriate methods from the `pandas`, `matplotlib`, and `sklearn` libraries to analyze and process the dataset for building predictive models.\n",
    "\n",
    "\n",
    "\n",
    "**Format**: Use this Jupyter Notebook as a template to write your report in `Markdown` cells, supported by your source code in Code cells. Ensure your code produces the corresponding plots or results addressing the questions. Rename this .ipynb file to `202425_COMP1008_cw_XXX.ipynb`, where XXX is your username (e.g., psxyz), and submit it to Moodle by <b><font color = \"red\">24 March, 3pm</font></b>.\n",
    "\n",
    "**Marks**: The coursework is worth a total of 100 marks (accounting for 25% of the COMP1008 module grade). Marks will be awarded based on your understanding of machine learning theories, the informativeness and presentation of your code, visualizations, results (e.g., code comments, necessary labels in plots), self-learning ability in solving the specific problem, as well as, how succinct, concise, and clear is your report writing.\n",
    "\n",
    "Please check the detailed instructions at the end of this template file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"text-align:left;\">\n",
    "<h2>Question 1. Prediction Model 1 - Linear Regression Model<span style=\"float:right;\">[50 marks]</span></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1a <span style=\"color:red\">(5 marks)</span> \n",
    "**TASK**: Briefly explain why the Red Wine Quality dataset is suitable for linear regression analysis.\n",
    "- Identify at least 3 characteristics that make this dataset appropriate for regression.\n",
    "- Use 3 bullet points (one for each characteristics) to present your answer concisely.\n",
    "- Your explanation should reflect your understanding of the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1a Answer</b>: Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous Numerical Values**    \n",
    "The data set has continuous numerical values which allows values to be plotted and analysed to create an equation for the line generated from linear regression techniques. This makes it appropriate because linear regression essentially constructs a line with a linear equation to try and plot a relationship between some given attributes, so the more points and the wider range of points that the algorithm is given the more accurately it will be able to generate a line representing the relationship between the given inputs and the selected output\n",
    "\n",
    "**Clear Target Values**    \n",
    "By having a clear target value - 'quality' attribute - it means that the system will be able to calculate a 'loss' value to see how good the generated equation is at predecting the relationship between the set of inputs and the output which means that the algorithm can look at the current loss and previous loss to see if it has decreased and if it has then the algorithm knows for the next iteration aswell to shift the regression line further in that direction so that it isn't blindly guessing which way will improve the accuracy of the predicted relationship.   \n",
    "\n",
    "**Likely Linear Relation**\n",
    "Lots of the potential input attributes within the dataset are likely to be linearly related meaning there likely exists a linear equation that can plot the overall relationship between the inputs of the wine data set and the outputs. So a linear regression model will be able to pretty accurately predict the relationship aswell as its aim is to try and establish the linear relationship between attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1b <span style=\"color:red\">(15 marks)</span>\n",
    "\n",
    "**TASK**: Analyze the dataset using appropriate methods from the `pandas` and/or `matplotlib` libraries. \n",
    "- Identify potential issues with the current dataset, specify which part(s) of the dataset are affected. Explain what could go wrong if the data is not properly pre-processed.\n",
    "- Provide at least 2 short-code solutions demonstrating how you analyze these issues.  \n",
    "- Briefly explain how each code snippet helps evaluate data quality issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1b answer</b>: Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Issues Within the Current Dataset\n",
    "**NaN Values**\n",
    "\n",
    "`Not A Number` values exist within the data set such as within the `density` or the `free sulfur dioxide` attribute.\n",
    "\n",
    "If pre-processing isn't applied to remove the `NaN` values from the dataset then this could break the model because if an input is `Not a Number` then the formula (equation of the regression line) cannot be used to predicted the output value of an input which would cause the program to crash.1\n",
    "\n",
    "\n",
    "**Outliers Within the Dataset**\n",
    "\n",
    "Some values within the dataset have extreme values/outliers - such as in the `chlorides` or `sulphates` columns - which can make it harder for the algorithm to develop a linear regression line for the dataset, so these values will need to be identified and then removed from the data set to avoid harming the model.\n",
    "\n",
    "If pre-processing isn't properly applied then the outliers can skew the predicted relationship between the inputs and the outputs resulting in inaccurate predictions for a given set of inputs.\n",
    "\n",
    "\n",
    "**Not Normally Distributed**\n",
    "\n",
    "Some of the data for attributes such as `residual sugar` have skewed data distributions and linear regression generally assumes that data is normally distributed across the dataset.\n",
    "\n",
    "If pre-processing isn't properly applied then the model may be more sensitive to the outliers/extreme values present in some columns as it will try to create a linear relationship that can satisfy both extreme and normal values therefore the regression line will end up somewhere in between the extreme and normal values therefore it's predictions could be inaccurate.\n",
    "\n",
    "\n",
    "**Duplicate Values**\n",
    "\n",
    "If any duplicate rows exist within the dataframe this could become an issue when the algorithm begins to try and map the linear relationship between the inputs and the outputs. This is because by having duplicate rows the system may become bias towards the over duplicates as they appear more often so the algorithm then believes they should be more common, however in reality they may not be. Another issue that arises from having duplicate values is that the model can **overfit** to that specific data entry meaning that the performance metrics - such as `loss` - may be over inflated because for the test data the regression line would be very good at predicting a single combination of inputs' output values however on unseen data it may not perform as well due to over-representation of a single row within the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "wineQualDf = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# run to set up the data frame to be pre-processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting NaN Values**\n",
    "\n",
    "The `countNaNRows()` takes in the data frame to be analysed and then uses the `df.isna()` function to create a dataframe of booleans identifiying whether the value at the corresponding location is a `NaN` value or not. Then the `.any(axis=1)` function is applied which conceptually flattens a dataframe into a list by looking at a row - determined by axis = 0 for columns or axis = 1 for rows - of a given index within the dataframe and then if any of the values in that row are `True` then the corresponding index in the created list will be `True` aswell, otherwise the corresponding index is set to `False`. This then means that the `.sum()` function can be applied as it is now operating on a list/array which takes `True = 1` and `False = 0` so by totalling the list it gives us the number of rows that contain `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(275)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countNaNRows(df):\n",
    "    NaNCount = df.isna().any(axis=1).sum()\n",
    "    return NaNCount\n",
    "\n",
    "\n",
    "countNaNRows(wineQualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting Outliers**\n",
    "\n",
    "When removing outliers, once abstracted, the larger problem isn't removing the values from the dataframe but identifying and establishing what constitutes an outlier.\n",
    "\n",
    "In the code snippet above an outlier is identified as a value that is either:\n",
    "- *greater than the third quartile of the dataset plus 3 × the interquartile range*\n",
    "- *less than the first quartile of the dataset minus 3 × the interquartile range*\n",
    "\n",
    "The function `countOutlierRows` counts the number of rows that would be removed due to containing values that would be classified as 'outliers' by the program, this is done by first getting the quantiles of the passed in dataframe and then calculates the interquartile range. Next it generates a boolean mask with values that meet either condition specified. It then calls the `.sum()` function to finally count the number of rows that would be removed from the data frame due to containing values that constitute outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(169)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countOutlierRows(df) -> pd.DataFrame:\n",
    "    quart1 = df.quantile(0.25)\n",
    "    quart3 = df.quantile(0.75)\n",
    "\n",
    "    IQrange = quart3 - quart1\n",
    "\n",
    "    lowerBound = quart1-3*IQrange\n",
    "    upperBound = quart3+3*IQrange\n",
    "\n",
    "    outlierCount = ((df<lowerBound) | (df>upperBound)).any(axis=1).sum()\n",
    "\n",
    "    return outlierCount\n",
    "\n",
    "\n",
    "countOutlierRows(wineQualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting the Number of Duplicate Rows**\n",
    "\n",
    "The function below - `countDuplicateRows` - counts the number of occurences of duplicate rows within the dataframe, this is done by using the inbuilt `.duplicated()` function that evaluates every row within a data frame to see if there has been an occurence of the same row before. This then returns a `series` that similarly to the `.any()` function has each element either evaluate to either `True` or `False` which - then again - can have the `.sum()` function applied to it which then essentially counts the number of occurences of `True` values which represnets the number of rows that are duplicated.\n",
    "\n",
    "So for example in the dataframe:\n",
    "    *'A': [1, 2, 3, 1, 2],*\n",
    "    *'B': ['a', 'b', 'c', 'a', 'b']*\n",
    "\n",
    "the output of the `countDuplicateRows()` would be 2 because there are 2 occurences of data duplication within the dataframe - `Row 4` is a duplicate of `Row 1` (1,a) and then `Row 5` is a copy of `Row 2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countDuplicateRows(df):\n",
    "    dupeCount = df.duplicated().sum()\n",
    "    return dupeCount\n",
    "\n",
    "countDuplicateRows(wineQualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1c <span style=\"color:red\">(20 marks)</span>\n",
    "**TASK**: Apply appropriate data preprocessing techniques to address the issues identified in Question 1b.\n",
    "- Provide a code solution that resolves the identified data issue(s).\n",
    "- Briefly explain the methods and parameters used in your solution. Ensure your explanation clearly justifies how these techniques improve data quality and suitability for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1c answer</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countNaNRows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 83\u001b[0m\n\u001b[0;32m     78\u001b[0m     df \u001b[38;5;241m=\u001b[39m removeDuplicateRows(df)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 83\u001b[0m \u001b[43mperformPreProcessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwineQualDf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 76\u001b[0m, in \u001b[0;36mperformPreProcessing\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mperformPreProcessing\u001b[39m(df):\n\u001b[1;32m---> 76\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mNaNhandling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandleNaNValues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     df \u001b[38;5;241m=\u001b[39m outlierHandling\u001b[38;5;241m.\u001b[39mhandleOutliers(df)\n\u001b[0;32m     78\u001b[0m     df \u001b[38;5;241m=\u001b[39m removeDuplicateRows(df)\n",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m, in \u001b[0;36mNaNhandling.handleNaNValues\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandleNaNValues\u001b[39m(df):\n\u001b[0;32m     14\u001b[0m     handleMethod \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcountNaNRows\u001b[49m(df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handleMethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'countNaNRows' is not defined"
     ]
    }
   ],
   "source": [
    "class NaNhandling():\n",
    "    @staticmethod\n",
    "    def handleNaNmodal(df):\n",
    "        correctedDf = df.apply(lambda x: x.fillna(x.mode()[0],axis=0))\n",
    "        return correctedDf\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def handleNaNdrop(df):\n",
    "        return df.dropna()\n",
    "    \n",
    "    @staticmethod\n",
    "    def handleNaNValues(df):\n",
    "        handleMethod = 'modal'\n",
    "        \n",
    "        if countNaNRows(df) == 0:\n",
    "            return df\n",
    "        \n",
    "        if handleMethod == 'modal':\n",
    "            return NaNhandling.handleNaNmodal(df)\n",
    "\n",
    "        elif handleMethod == 'drop':\n",
    "            return NaNhandling.handleNaNdrop(df)\n",
    "        \n",
    "\n",
    "class outlierHandling():\n",
    "    @staticmethod\n",
    "    def getUpperLowerBounds(df):\n",
    "        quart1 = df.quantile(0.25)\n",
    "        quart3 = df.quantile(0.75)\n",
    "\n",
    "        IQrange = quart3 - quart1\n",
    "\n",
    "        lowerBound = quart1-3*IQrange\n",
    "        upperBound = quart3+3*IQrange      \n",
    "\n",
    "        return lowerBound,upperBound\n",
    "\n",
    "    @staticmethod\n",
    "    def handleOutliersModal(df):\n",
    "        \n",
    "        lowerBound,upperBound = outlierHandling.getUpperLowerBounds(df)\n",
    "    \n",
    "        for col in df.columns:\n",
    "            modalVal = df[col].mode()[0]\n",
    "            df[col] = df[col].apply(lambda x: modalVal if x<lowerBound[col] or x>upperBound[col] else x)\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def handleOutliersDrop(df):\n",
    "        lowerBound,upperBound = outlierHandling.getUpperLowerBounds(df)\n",
    "        strippedDf = df[~((df<lowerBound | df>upperBound)).any(axis=1)]\n",
    "        return strippedDf\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def handleOutliers(df):\n",
    "        handleMethod = 'modal'\n",
    "\n",
    "        if countDuplicateRows(df) == 0:\n",
    "            return df\n",
    "        \n",
    "        if handleMethod == 'modal':\n",
    "            return outlierHandling.handleOutliersModal(df)\n",
    "        \n",
    "        elif handleMethod == 'drop':\n",
    "            return outlierHandling.handleOutliersDrop(df)\n",
    "\n",
    "        \n",
    "def removeDuplicateRows(df):\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "\n",
    "def performPreProcessing(df):\n",
    "    df = NaNhandling.handleNaNValues(df)\n",
    "    df = outlierHandling.handleOutliers(df)\n",
    "    df = removeDuplicateRows(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "performPreProcessing(wineQualDf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1d <span style=\"color:red\">(10 marks)</span>\n",
    "\n",
    "**TASK**: Train and evaluate a Linear Regression model using the preprocessed dataset.   \n",
    "- Print the model's weights.  \n",
    "- Print the model's accuracy. \n",
    "    - Evaluate the model using at least three different metrics.\n",
    "    - Briefly discuss the advantages of each metric in assessing model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1d answer</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"text-align:left;\"><h2>Question 2. Prediction Model 2<span style=\"float:right;\">[20 marks]</span></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2a <span style=\"color:red\">(10 marks)</span>\n",
    "\n",
    "**TASK**: Build a different machine learning model for the same prediction task.\n",
    "- Choose a model covered in the lectures or explain your choice of a different method. If you choose a different method, provide at at least two arguments to justify your choice compared to the ones covered in the lectures. \n",
    "- Specify which model you selected and why. \n",
    "- List the key parameters of your chosen model (Model 2).\n",
    "- Provide a code implementation for the selected method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q2a answer</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b <span style=\"color:red\">(10 marks)</span>\n",
    "**TASK**: Evaluate the performance of your new model and compare it to Prediction Model 1.\n",
    "- Analyze whether the new model performs better or worse and explain why.\n",
    "    - Base your evaluation on the same metrics used in Question 1d).\n",
    "- Include one plot visually comparing the performance of both models.\n",
    "- Provide a brief textual explanation interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q2b answer</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"text-align:left;\"><h2>Question 3. Comparison and Improvement<span style=\"float:right;\">[30 marks]</span></h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Question 3a <span style=\"color:red\">(15 marks)</span>\n",
    "**TASK**: Analyze the impact of removing the least important feature from Prediction Model 1.\n",
    "- Identify and remove the least important feature. \n",
    "- Retrain the Linear Regression model and evaluate its performance. \n",
    "- Compare the results before and after feature removal.\n",
    "- Provide a code implementation and a justification explaining the impact on model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3a answer</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b <span style=\"color:red\">(15 marks)</span>\n",
    "**TASK**: Based on your observations, suggest strategies for improving future models when predicting on new data.\n",
    "- Discuss potential improvements. \n",
    "\n",
    "<b>Hint</b>: based on relevant analysis, feature selection, feature scaling and data processing (e.g. resolve imbalanced samples, errors and outliers, etc.) could all potentially improve the model by reducing training time, fixing overfitting and improving interpretability, etc. \n",
    "You can also explore external resources for other potential approaches or techniques.<br>\n",
    "\n",
    "<b>Note</b>: Coding is optional here, but your answers should be supported by relevant analysis or justifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3b answer</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix. Coursework Instructions\n",
    "\n",
    "<b>Coursework Support</b>:\n",
    "- COMP1008 computing tutorials and exercises on data processing and machine learning models on different example problems\n",
    "- Example code building and analysing machine learning models in COMP1008 lectures slides on 'Machine learning'\n",
    "- In the computing sessions, Q&A support for developing .ipynb projects\n",
    "- In Teams channel 'COMP1008 2024/25 / Questions': support of common questions\n",
    "\n",
    "<b>Marks</b>: in total 100 marks (count for 25% in COMP1008), awarded on the basis of:\n",
    "- knowledge and understanding on the theories covered in lectures when answering the questions in the Jupyter Notebook report\n",
    "- how informative and well presented your code, visualisations and results are (e.g. necessary labels in plots)\n",
    "- self-learning ability making use of tutorial materials and online resources\n",
    "- problem solving skills to obtain the answers and results for the specific dataset\n",
    "- concise report with key details, e.g. parameters, data, etc. for others to repeat your methods and obtain the same results.\n",
    "\n",
    "For more information of COMP1008 assessment please refer to the coursework issue in Moodle ('Course Content / Assessment')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Format</b>:\n",
    "- One single .ipynb file named 202425_COMP1008_cw_XXX.ipynb, where XXX is your username (e.g. psxyz)\n",
    "- The .ipynb file should include your code and answers, using this given .ipynb template (please add cells as needed)\n",
    "- You could use additional Python libraries as you wish, in addition to the ones demonstrated in the computing sessions\n",
    "- There are multiple ways using different methods to complete the tasks. These are fine as long as all answers and analysis are supported by the code implemented in Jupyter Notebook, not by using other means (e.g. operations in Excel, or by using other languages, etc.).\n",
    "\n",
    "<b>Submission</b>: \n",
    "- Deadline: <b><font color = \"red\">24 March, 3pm</font></b>.\n",
    "- Late submission leads to a 5% deduction of the coursework on each weekday. Work submitted one week late will receive a 0 for the coursework.\n",
    "- Method: in Moodle submit a single .ipynb file named 202425_COMP1008_cw_XXX.ipynb\n",
    "- If you can’t submit your coursework on time due to ECs, please contact Student Services and your personal tutor ASAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<b>Note: Plagiarism vs. Group Discussions</b> \n",
    "\n",
    "As you should know, plagiarism is completely unacceptable and will be dealt with according to University's standard policies.<br>\n",
    "Students are encouraged to have only general discussions on the theory (not the specific questions) when completing the coursework.<br>\n",
    "It is important that when you actually do your coursework and write the answers, you do it individually.<br>\n",
    "Do NOT, under any circumstances, share your report, code or figures, etc. with anyone else."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
